{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "from pandas import read_stata\n",
    "import numpy as np\n",
    "from pygrowup import Calculator\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg', warn=False)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from lab09_minimize import *\n",
    "\n",
    "def minimize_multi(f, start=None, **vargs):\n",
    "  def expanded_f(*args):\n",
    "    return f(args)\n",
    "  return minimize(expanded_f, start=start, method=\"L-BFGS-B\", **vargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Household ID</th> <th>Individual ID</th> <th>Day of Birth</th> <th>Month of Birth</th> <th>Birth Year</th> <th>Age in Years</th> <th>Sex</th> <th>Height</th> <th>Weight</th> <th>Relationship to HH Head</th> <th>Mother ID</th> <th>Father ID</th> <th>Currently Enrolled in School</th> <th>Years of Schooling - Level</th> <th>Years of Schooling - Years</th> <th>Master ID</th> <th>Day of Interview</th> <th>Month of Interview</th> <th>Year of Interview</th> <th>Days Old</th> <th>Years Old</th> <th>Months Old</th> <th>z_scores</th> <th>Rounded Months</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>20111642    </td> <td>3            </td> <td>3           </td> <td>7             </td> <td>1976      </td> <td>31          </td> <td>2   </td> <td>1     </td> <td>-99   </td> <td>9                      </td> <td>-99      </td> <td>-99      </td> <td>-99                         </td> <td>2                         </td> <td>5                         </td> <td>-1363194477</td> <td>10              </td> <td>7                 </td> <td>2007             </td> <td>11329.8 </td> <td>31.0404  </td> <td>59        </td> <td>-22.86  </td> <td>59            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>20111642    </td> <td>4            </td> <td>10          </td> <td>9             </td> <td>1995      </td> <td>11          </td> <td>2   </td> <td>1     </td> <td>-99   </td> <td>5                      </td> <td>3        </td> <td>2        </td> <td>1                           </td> <td>-99                       </td> <td>-99                       </td> <td>-1363194476</td> <td>10              </td> <td>7                 </td> <td>2007             </td> <td>4322    </td> <td>11.8411  </td> <td>59        </td> <td>-22.86  </td> <td>59            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>20111642    </td> <td>5            </td> <td>20          </td> <td>4             </td> <td>1997      </td> <td>10          </td> <td>1   </td> <td>1     </td> <td>-99   </td> <td>5                      </td> <td>3        </td> <td>2        </td> <td>1                           </td> <td>-99                       </td> <td>-99                       </td> <td>-1363194475</td> <td>10              </td> <td>7                 </td> <td>2007             </td> <td>3734    </td> <td>10.2301  </td> <td>59        </td> <td>-23.58  </td> <td>59            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>20111642    </td> <td>6            </td> <td>26          </td> <td>12            </td> <td>1999      </td> <td>7           </td> <td>1   </td> <td>1     </td> <td>-99   </td> <td>5                      </td> <td>3        </td> <td>2        </td> <td>-99                         </td> <td>-99                       </td> <td>-99                       </td> <td>-1363194474</td> <td>10              </td> <td>7                 </td> <td>2007             </td> <td>2753.5  </td> <td>7.54384  </td> <td>59        </td> <td>-23.58  </td> <td>59            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>20111642    </td> <td>7            </td> <td>17          </td> <td>1             </td> <td>2000      </td> <td>7           </td> <td>1   </td> <td>1     </td> <td>-99   </td> <td>5                      </td> <td>3        </td> <td>2        </td> <td>-99                         </td> <td>-99                       </td> <td>-99                       </td> <td>-1363194473</td> <td>10              </td> <td>7                 </td> <td>2007             </td> <td>2732.75 </td> <td>7.48699  </td> <td>59        </td> <td>-23.58  </td> <td>59            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>20111642    </td> <td>8            </td> <td>26          </td> <td>5             </td> <td>2002      </td> <td>5           </td> <td>1   </td> <td>105.9 </td> <td>22.6  </td> <td>5                      </td> <td>3        </td> <td>2        </td> <td>-99                         </td> <td>-99                       </td> <td>-99                       </td> <td>-1363194472</td> <td>10              </td> <td>7                 </td> <td>2007             </td> <td>1871.25 </td> <td>5.12671  </td> <td>59        </td> <td>-0.76   </td> <td>59            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>20111642    </td> <td>9            </td> <td>5           </td> <td>1             </td> <td>2005      </td> <td>2           </td> <td>2   </td> <td>80.5  </td> <td>9.5   </td> <td>5                      </td> <td>3        </td> <td>2        </td> <td>-99                         </td> <td>-99                       </td> <td>-99                       </td> <td>-1363194471</td> <td>10              </td> <td>7                 </td> <td>2007             </td> <td>918.5   </td> <td>2.51644  </td> <td>30.1148   </td> <td>-2.88   </td> <td>30            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>20111642    </td> <td>10           </td> <td>12          </td> <td>4             </td> <td>2006      </td> <td>1           </td> <td>2   </td> <td>70.3  </td> <td>7.1   </td> <td>5                      </td> <td>3        </td> <td>2        </td> <td>-99                         </td> <td>-99                       </td> <td>-99                       </td> <td>-1363194470</td> <td>10              </td> <td>7                 </td> <td>2007             </td> <td>454.75  </td> <td>1.24589  </td> <td>14.9098   </td> <td>-2.27   </td> <td>15            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>20113642    </td> <td>1            </td> <td>13          </td> <td>4             </td> <td>1966      </td> <td>41          </td> <td>1   </td> <td>1     </td> <td>-99   </td> <td>1                      </td> <td>-99      </td> <td>-99      </td> <td>-99                         </td> <td>-99                       </td> <td>-99                       </td> <td>-1361194479</td> <td>10              </td> <td>7                 </td> <td>2007             </td> <td>15063.8 </td> <td>41.2705  </td> <td>59        </td> <td>-23.58  </td> <td>59            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>20113642    </td> <td>2            </td> <td>1           </td> <td>1             </td> <td>1969      </td> <td>38          </td> <td>2   </td> <td>1     </td> <td>-99   </td> <td>2                      </td> <td>-99      </td> <td>-99      </td> <td>-99                         </td> <td>-99                       </td> <td>-99                       </td> <td>-1361194478</td> <td>10              </td> <td>7                 </td> <td>2007             </td> <td>14071.5 </td> <td>38.5521  </td> <td>59        </td> <td>-22.86  </td> <td>59            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (23002 rows omitted)</p"
      ],
      "text/plain": [
       "Household ID | Individual ID | Day of Birth | Month of Birth | Birth Year | Age in Years | Sex  | Height | Weight | Relationship to HH Head | Mother ID | Father ID | Currently Enrolled in School | Years of Schooling - Level | Years of Schooling - Years | Master ID   | Day of Interview | Month of Interview | Year of Interview | Days Old | Years Old | Months Old | z_scores | Rounded Months\n",
       "20111642     | 3             | 3            | 7              | 1976       | 31           | 2    | 1      | -99    | 9                       | -99       | -99       | -99                          | 2                          | 5                          | -1363194477 | 10               | 7                  | 2007              | 11329.8  | 31.0404   | 59         | -22.86   | 59\n",
       "20111642     | 4             | 10           | 9              | 1995       | 11           | 2    | 1      | -99    | 5                       | 3         | 2         | 1                            | -99                        | -99                        | -1363194476 | 10               | 7                  | 2007              | 4322     | 11.8411   | 59         | -22.86   | 59\n",
       "20111642     | 5             | 20           | 4              | 1997       | 10           | 1    | 1      | -99    | 5                       | 3         | 2         | 1                            | -99                        | -99                        | -1363194475 | 10               | 7                  | 2007              | 3734     | 10.2301   | 59         | -23.58   | 59\n",
       "20111642     | 6             | 26           | 12             | 1999       | 7            | 1    | 1      | -99    | 5                       | 3         | 2         | -99                          | -99                        | -99                        | -1363194474 | 10               | 7                  | 2007              | 2753.5   | 7.54384   | 59         | -23.58   | 59\n",
       "20111642     | 7             | 17           | 1              | 2000       | 7            | 1    | 1      | -99    | 5                       | 3         | 2         | -99                          | -99                        | -99                        | -1363194473 | 10               | 7                  | 2007              | 2732.75  | 7.48699   | 59         | -23.58   | 59\n",
       "20111642     | 8             | 26           | 5              | 2002       | 5            | 1    | 105.9  | 22.6   | 5                       | 3         | 2         | -99                          | -99                        | -99                        | -1363194472 | 10               | 7                  | 2007              | 1871.25  | 5.12671   | 59         | -0.76    | 59\n",
       "20111642     | 9             | 5            | 1              | 2005       | 2            | 2    | 80.5   | 9.5    | 5                       | 3         | 2         | -99                          | -99                        | -99                        | -1363194471 | 10               | 7                  | 2007              | 918.5    | 2.51644   | 30.1148    | -2.88    | 30\n",
       "20111642     | 10            | 12           | 4              | 2006       | 1            | 2    | 70.3   | 7.1    | 5                       | 3         | 2         | -99                          | -99                        | -99                        | -1363194470 | 10               | 7                  | 2007              | 454.75   | 1.24589   | 14.9098    | -2.27    | 15\n",
       "20113642     | 1             | 13           | 4              | 1966       | 41           | 1    | 1      | -99    | 1                       | -99       | -99       | -99                          | -99                        | -99                        | -1361194479 | 10               | 7                  | 2007              | 15063.8  | 41.2705   | 59         | -23.58   | 59\n",
       "20113642     | 2             | 1            | 1              | 1969       | 38           | 2    | 1      | -99    | 2                       | -99       | -99       | -99                          | -99                        | -99                        | -1361194478 | 10               | 7                  | 2007              | 14071.5  | 38.5521   | 59         | -22.86   | 59\n",
       "... (23002 rows omitted)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Table.read_table('Lab_3.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Regression\n",
    "\n",
    "<font color=\"Blue\"> Another way to predict outcomes is with multivariate regression.  Prepare two multivariate regressions to compare: one regression will have all the variables you think are important and the other will have variables you think are not important.  Compare the R^2 of these regressions.  Were you right? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at the steps to building multivariate regression examining how age and sex predict height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Height</th> <th>Age in Years</th> <th>Sex</th> <th>For Intercept</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>105   </td> <td>5           </td> <td>1   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>80    </td> <td>2           </td> <td>2   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>70    </td> <td>1           </td> <td>2   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>113   </td> <td>5           </td> <td>1   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>89    </td> <td>3           </td> <td>1   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>74    </td> <td>1           </td> <td>2   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>89    </td> <td>3           </td> <td>1   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>87    </td> <td>2           </td> <td>1   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>112   </td> <td>5           </td> <td>1   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>85    </td> <td>3           </td> <td>2   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (4288 rows omitted)</p"
      ],
      "text/plain": [
       "Height | Age in Years | Sex  | For Intercept\n",
       "105    | 5            | 1    | 1\n",
       "80     | 2            | 2    | 1\n",
       "70     | 1            | 2    | 1\n",
       "113    | 5            | 1    | 1\n",
       "89     | 3            | 1    | 1\n",
       "74     | 1            | 2    | 1\n",
       "89     | 3            | 1    | 1\n",
       "87     | 2            | 1    | 1\n",
       "112    | 5            | 1    | 1\n",
       "85     | 3            | 2    | 1\n",
       "... (4288 rows omitted)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure all your data is in integer format and keep only observations with height, age & sex data\n",
    "data[\"Height\"]=data.apply(int, 'Height')\n",
    "data[\"Age in Years\"]=data.apply(int, 'Age in Years')\n",
    "data[\"Sex\"]=data.apply(int, 'Sex')\n",
    "# Make a column that will be associated with the intercept\n",
    "data[\"For Intercept\"]=1\n",
    "\n",
    "# Select all the variables you want to analyze including intercept and outcome.\n",
    "# (Until we have the correct minimizing function, just include one variable and the outcome.)\n",
    "data=data.select(\"Height\",\"Age in Years\",\"Sex\",\"For Intercept\")\n",
    "data=data.where(data['Height']>10)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Age in Years</th> <th>Sex</th> <th>For Intercept</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>5           </td> <td>1   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>2           </td> <td>2   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>1           </td> <td>2   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>5           </td> <td>1   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>3           </td> <td>1   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>1           </td> <td>2   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>3           </td> <td>1   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>2           </td> <td>1   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>5           </td> <td>1   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>3           </td> <td>2   </td> <td>1            </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (4288 rows omitted)</p"
      ],
      "text/plain": [
       "Age in Years | Sex  | For Intercept\n",
       "5            | 1    | 1\n",
       "2            | 2    | 1\n",
       "1            | 2    | 1\n",
       "5            | 1    | 1\n",
       "3            | 1    | 1\n",
       "1            | 2    | 1\n",
       "3            | 1    | 1\n",
       "2            | 1    | 1\n",
       "5            | 1    | 1\n",
       "3            | 2    | 1\n",
       "... (4288 rows omitted)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide the table in two: predictor variables (sex & age) & outcome variable (height)\n",
    "X_features_table =data.drop(\"Height\")\n",
    "X_true_values = data.column(\"Height\") # note: this is an array\n",
    "X_features_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose some intial values for maximizing the coefficients \n",
    "# An easy choice is all 0's.  \n",
    "# There will be the same number of coefficients as there are predictors - a slope for each predictor.\n",
    "X_initial_coefficient_guess = np.zeros(X_features_table.num_columns)\n",
    "X_initial_coefficient_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_all(features_table, coefficients):\n",
    "    \"\"\"\n",
    "    Given a table of features called features_table and some coefficients,\n",
    "    produces linear predictions for each row of features_table.\n",
    "    \n",
    "    features_table should be a table with one column for each feature\n",
    "    being used to predict.  Each row represents a house in the task\n",
    "    we're doing in this lab.\n",
    "    \n",
    "    coefficients should be an array with one element for each column in\n",
    "    features_table, like the coefficients computed by the function\n",
    "    least_squares_coefficients.\n",
    "    \n",
    "    Returns an array of predictions, one for each row of features_table.\n",
    "    \n",
    "    For example, in the house price prediction task we're working on in\n",
    "    this lab, each row of data is the features of one house sale, like\n",
    "    the number of bedrooms or the size of the house.  To make a\n",
    "    prediction for the price of a house, we multiply each of these\n",
    "    features by the corresponding coefficient in the coefficients\n",
    "    array, then sum the results.\n",
    "    \n",
    "    An even more detailed example: Suppose we have just one house whose\n",
    "    price we want to predict, and two features, Bedrooms and Size.\n",
    "    Then features_table will have 1 row and 2 columns, Bedrooms and Size.\n",
    "    Say their values are 2 and 1500.  The coefficients array will have 2\n",
    "    numbers in it, say -1000 and 200.  Our prediction for this house is:\n",
    "\n",
    "        features_table.column(0).item(0)*coefficients.item(0) + \\\n",
    "        data.column(1).item(0)*coefficients.item(1)\n",
    "    \n",
    "    or\n",
    "    \n",
    "        2*-1000 + 1500*200\n",
    "    \n",
    "    which is $298,000.  So we will return an array with just one number\n",
    "    in it, and it will look like:\n",
    "    \n",
    "        np.array([298000])\n",
    "    \n",
    "    If there were 3 rows in features_table, we would return a 3-element\n",
    "    array instead, containing the predicted prices for each row.\n",
    "    \"\"\"\n",
    "   # assert features_table.num_columns == len(coefficients), /\n",
    "    \"\"\"\n",
    "    The first argument to predict_all should be a table with one\n",
    "    column for each feature.  That means it should have the same\n",
    "    number of columns as the coefficients array (the second\n",
    "    argument) has elements.\n",
    "    \"\"\"\n",
    "    def predict(features):\n",
    "        # Given an array of features, produce one prediction.\n",
    "        return sum(features * coefficients)\n",
    "    predictions = Table().with_column('features', features_table.rows).apply(predict, 'features')\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_predictions=predict_all(X_features_table, X_initial_coefficient_guess)\n",
    "X_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 5, 4, ..., 3, 4, 3])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the initial coefficient guess up above to make a different prediction!\n",
    "X_new_coefficient_guess = [1]\n",
    "X_predictions=predict_all(X_features_table, X_new_coefficient_guess)\n",
    "X_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_errors(features_table, coefficients, true_values):\n",
    "    \"\"\"\n",
    "    Computes the prediction errors for a linear model with the given\n",
    "    coefficients when predicting the true values for the given\n",
    "    examples.\n",
    "    \n",
    "    features_table should be a table with one column for each feature\n",
    "    being used to predict.  Each row represents a house in the task\n",
    "    we're doing in this lab.\n",
    "    \n",
    "    coefficients should be an array of numbers, one for each feature.\n",
    "    \n",
    "    true_values should be an array of numbers, one for each row in\n",
    "    features_table.  It records the true prices of each house.\n",
    "    \"\"\"\n",
    "    return predict_all(features_table, coefficients) - true_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-105.,  -80.,  -70., ...,  -69.,  -83.,  -74.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_errors=compute_errors(X_features_table, X_initial_coefficient_guess, X_true_values)\n",
    "X_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(errors):\n",
    "    \"\"\"\n",
    "    Computes the root mean squared error when a regression model makes\n",
    "    the given errors.  So errors should be an array of numbers, one for\n",
    "    each row in some data table for which we're computing predictions\n",
    "    (that is, each house).  Each number is the prediction error of some\n",
    "    regression model (when predicting the price of a house).\n",
    "    \"\"\"\n",
    "    return np.mean(errors**2)**0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.002087362612187"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2=rmse(X_errors)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_least_squares_objective_function(features_table, true_values):\n",
    "    \"\"\"\n",
    "    Makes an objective function for training data in the features_table\n",
    "    table, where the true values we're trying to predict are true_values.\n",
    "    \n",
    "    features_table should be a table with one column for each feature\n",
    "    being used to predict.  Each row represents a house in the task\n",
    "    we're doing in this lab.\n",
    "    \n",
    "    true_values should be an array of numbers, one for each row in\n",
    "    features_table.  It records the true prices of each house.\n",
    "    \n",
    "    The returned value is a function.  That function takes an array of\n",
    "    coefficients and returns a number.  Larger values of that number\n",
    "    mean that those coefficients produce worse prediction errors.\n",
    "    \"\"\"\n",
    "    def objective_function(coefficients):\n",
    "        errors = compute_errors(features_table, np.array(coefficients), true_values)\n",
    "        return rmse(errors)\n",
    "    return objective_function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.make_least_squares_objective_function.<locals>.objective_function>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_objective_function = make_least_squares_objective_function(X_features_table, X_true_values)\n",
    "X_objective_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares_coefficients(training_data, predicted_column_name):\n",
    "    \"\"\"\n",
    "    Performs multiple linear regression predicting predicted_column_name\n",
    "    using the other columns of training_data as features.\n",
    "    \n",
    "    training_data should be a table with one column for each feature\n",
    "    being used to predict, plus one column for the value we're trying\n",
    "    to predict.  That column's name should equal predicted_column_name.\n",
    "    Each row represents a house in the task we're doing in this lab.\n",
    "    \n",
    "    predicted_column_name should be a string, the name of the column in\n",
    "    training_data that we're trying to predict.\n",
    "    \n",
    "    Returns an array of coefficients, one for each feature (that is, one\n",
    "    for each column in training_data other than predicted_column_name).\n",
    "    \n",
    "    For example, if training_data has 3 columns, Bedroom, Size, and Price,\n",
    "    and predicted_column_name is \"Price\", then we will use Bedroom and\n",
    "    Size to predict Price.  This function will return an array of 2\n",
    "    numbers, a regression coefficient for Bedroom (like -1000) and a\n",
    "    regression coefficient for Size (like 200).\n",
    "    \"\"\"\n",
    "    features_table = training_data.drop(predicted_column_name)\n",
    "    true_values = training_data.column(predicted_column_name)\n",
    "    objective_function_OLS = make_least_squares_objective_function(features_table, true_values)\n",
    "    \n",
    "    # Now we find the coefficients that produce the smallest\n",
    "    # error.\n",
    "    initial_coefficient_guess = np.zeros(features_table.num_columns)\n",
    "    best_coefficients = minimize_multi(objective_function_OLS, start=initial_coefficient_guess)\n",
    "    if features_table.num_columns == 1:\n",
    "        return np.array([best_coefficients])\n",
    "    else:\n",
    "        return best_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.83037917,  -0.74819884,  67.83253874])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_best_coefficients = minimize_multi(X_objective_function, start=X_initial_coefficient_guess)\n",
    "X_best_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.83037917,  -0.74819884,  67.83253874])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "My_Coefficients = least_squares_coefficients(data, 'Height')\n",
    "My_Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well our model fits the data.  We will calculate the R^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.748953001396004"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_height=np.average(data[\"Height\"])\n",
    "mean_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Height</th> <th>Age in Years</th> <th>Sex</th> <th>For Intercept</th> <th>Predicted</th> <th>Diff_Predict_SQ</th> <th>Diff_True_SQ</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>105   </td> <td>5           </td> <td>1   </td> <td>1            </td> <td>106.236  </td> <td>1.52828        </td> <td>333.101     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>80    </td> <td>2           </td> <td>2   </td> <td>1            </td> <td>81.9969  </td> <td>3.98761        </td> <td>45.5484     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>70    </td> <td>1           </td> <td>2   </td> <td>1            </td> <td>74.1665  </td> <td>17.3599        </td> <td>280.527     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>113   </td> <td>5           </td> <td>1   </td> <td>1            </td> <td>106.236  </td> <td>45.7485        </td> <td>689.117     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>89    </td> <td>3           </td> <td>1   </td> <td>1            </td> <td>90.5755  </td> <td>2.48213        </td> <td>5.06721     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>74    </td> <td>1           </td> <td>2   </td> <td>1            </td> <td>74.1665  </td> <td>0.027729       </td> <td>162.536     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>89    </td> <td>3           </td> <td>1   </td> <td>1            </td> <td>90.5755  </td> <td>2.48213        </td> <td>5.06721     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>87    </td> <td>2           </td> <td>1   </td> <td>1            </td> <td>82.7451  </td> <td>18.1042        </td> <td>0.0630246   </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>112   </td> <td>5           </td> <td>1   </td> <td>1            </td> <td>106.236  </td> <td>33.221         </td> <td>637.615     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>85    </td> <td>3           </td> <td>2   </td> <td>1            </td> <td>89.8273  </td> <td>23.3026        </td> <td>3.05884     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (4288 rows omitted)</p"
      ],
      "text/plain": [
       "Height | Age in Years | Sex  | For Intercept | Predicted | Diff_Predict_SQ | Diff_True_SQ\n",
       "105    | 5            | 1    | 1             | 106.236   | 1.52828         | 333.101\n",
       "80     | 2            | 2    | 1             | 81.9969   | 3.98761         | 45.5484\n",
       "70     | 1            | 2    | 1             | 74.1665   | 17.3599         | 280.527\n",
       "113    | 5            | 1    | 1             | 106.236   | 45.7485         | 689.117\n",
       "89     | 3            | 1    | 1             | 90.5755   | 2.48213         | 5.06721\n",
       "74     | 1            | 2    | 1             | 74.1665   | 0.027729        | 162.536\n",
       "89     | 3            | 1    | 1             | 90.5755   | 2.48213         | 5.06721\n",
       "87     | 2            | 1    | 1             | 82.7451   | 18.1042         | 0.0630246\n",
       "112    | 5            | 1    | 1             | 106.236   | 33.221          | 637.615\n",
       "85     | 3            | 2    | 1             | 89.8273   | 23.3026         | 3.05884\n",
       "... (4288 rows omitted)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "My_predictions=predict_all(X_features_table, My_Coefficients)\n",
    "data[\"Predicted\"]=My_predictions\n",
    "data[\"Diff_Predict_SQ\"]=(data[\"Height\"]-data[\"Predicted\"])**2\n",
    "data[\"Diff_True_SQ\"]=(data[\"Height\"]-mean_height)**2\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79364575957588268"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_squared=1-np.sum(data[\"Diff_Predict_SQ\"])/np.sum(data[\"Diff_True_SQ\"])\n",
    "r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"Blue\"> Item 1: Let's be more systematic about building the model - we will add variables to try to get the largest R^2.  Adding more covariates will improve the fit of the model, but we are also making the model more complex.  Let's add covariates in order of importance, keeping those that increase the adjusted R^2.  The formula for the adjusted R^2 is 1-(1-R^2)(N-1)/(N-p-1), where N= sample size and p= number of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is of correlation, not causation.  But since this is a first indication of a potential causal relationship, we may as well try a policy and then later see if it works out. <font color=\"Blue\"> Item 2: If you were attempting to change the outcome based on changing the feature, which feature would you try to change?  Don't just consider the one with the highest correlation, but also take into account costs and difficulty of changing the feature. (Not a data exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"Blue\"> Item 3: Now trade coefficients with someone who is working with data from another country.  How well did their model fit your data: what is the accuracy of their model across borders? Comment on what this implies for policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"Blue\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
